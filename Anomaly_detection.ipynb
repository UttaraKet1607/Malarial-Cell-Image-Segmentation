{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anomaly_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOlwu8vhXaro/fCyUjofzr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UttaraKet1607/Malarial-Cell-Image-Segmentation/blob/main/Anomaly_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resources\n",
        "1. https://github.com/bnsreenu/python_for_microscopists/blob/master/260_image_anomaly_detection_using_autoencoders/260_image_anomaly_detection_using_autoencoders.py\n",
        "2. https://www.youtube.com/watch?v=q_tpFGHiRgg\n",
        "3. https://github.com/mayur7garg/MalariaCellImageClassification "
      ],
      "metadata": {
        "id": "N8XlnuQySH3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation"
      ],
      "metadata": {
        "id": "CiWW8ZjQSY9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "JIcaNg2KRYMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download iarunava/cell-images-for-detecting-malaria\n",
        "! unzip cell-images-for-detecting-malaria.zip"
      ],
      "metadata": {
        "id": "vCiRnM3JRYJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSVmRsD-PSyU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.mkdir('/content/cell_images/Train_Uninfected')"
      ],
      "metadata": {
        "id": "VvP_wIB0-ZqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# absolute path\n",
        "src_path = \"/content/cell_images/Uninfected\"\n",
        "dst_path = \"/content/cell_images/Train_Uninfected\"\n",
        "shutil.move(src_path, dst_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pQceMcvY-ZgV",
        "outputId": "33d83223-a96b-40b0-82ff-13e606a81d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/cell_images/Train_Uninfected/Train/Uninfected'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Size of our input images\n",
        "SIZE = 128\n",
        "\n",
        "#############################################################################\n",
        "#Define generators for training, validation and also anomaly data.\n",
        "\n",
        "batch_size = 64\n",
        "datagen_train = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_dir = '/content/cell_images/Train_Uninfected'\n",
        "test_dir = '/content/cell_images/Parasitized'\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(SIZE, SIZE),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = datagen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(SIZE, SIZE),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input',\n",
        "    subset='validation')\n",
        "\n",
        "anomaly_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(SIZE, SIZE),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQhkWDwbPrwM",
        "outputId": "9f1697ce-1f71-4017-df90-046b3271ad40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 1 classes.\n",
            "Found 0 images belonging to 1 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the autoencoder. \n",
        "#Try to make the bottleneck layer size as small as possible to make it easy for\n",
        "#density calculations and also picking appropriate thresholds. \n",
        "\n",
        "#Encoder\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3)))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "\n",
        "#Decoder\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))"
      ],
      "metadata": {
        "id": "aHPbPDYSP4pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "H17b6dzQP9qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model. \n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch= 500 // batch_size,\n",
        "        epochs=1000,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=75 // batch_size,\n",
        "        shuffle = True)"
      ],
      "metadata": {
        "id": "A516pz40P9nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-dmgiwsTQSos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all batches generated by the datagen and pick a batch for prediction\n",
        "#Just to test the model. \n",
        "data_batch = []  #Capture all training batches as a numpy array\n",
        "img_num = 0\n",
        "while img_num <= train_generator.batch_index:   #gets each generated batch of size batch_size\n",
        "    data = train_generator.next()\n",
        "    data_batch.append(data[0])\n",
        "    img_num = img_num + 1\n",
        "\n",
        "predicted = model.predict(data_batch[0])  #Predict on the first batch of images"
      ],
      "metadata": {
        "id": "5_Hqf2F3QXpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sanity check, view few images and corresponding reconstructions\n",
        "image_number = random.randint(0, predicted.shape[0])\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(data_batch[0][image_number])\n",
        "plt.subplot(122)\n",
        "plt.imshow(predicted[image_number])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VeVdKpAFQXjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us examine the reconstruction error between our validation data (good/normal images)\n",
        "# and the anomaly images\n",
        "validation_error = model.evaluate_generator(validation_generator)\n",
        "anomaly_error = model.evaluate_generator(anomaly_generator)\n",
        "\n",
        "print(\"Recon. error for the validation (normal) data is: \", validation_error)\n",
        "print(\"Recon. error for the anomaly data is: \", anomaly_error)"
      ],
      "metadata": {
        "id": "rLSXAlONQXiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us extract (or build) the encoder network, with trained weights.\n",
        "#This is used to get the compressed output (latent space) of the input image. \n",
        "#The compressed output is then used to calculate the KDE\n",
        "\n",
        "encoder_model = Sequential()\n",
        "encoder_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3), weights=model.layers[0].get_weights()) )\n",
        "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "encoder_model.add(Conv2D(32, (3, 3), activation='relu', padding='same', weights=model.layers[2].get_weights()))\n",
        "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "encoder_model.add(Conv2D(16, (3, 3), activation='relu', padding='same', weights=model.layers[4].get_weights()))\n",
        "encoder_model.add(MaxPooling2D((2, 2), padding='same'))\n",
        "encoder_model.summary()"
      ],
      "metadata": {
        "id": "okAXSdf6QwuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################\n",
        "# Calculate KDE using sklearn\n",
        "from sklearn.neighbors import KernelDensity\n",
        "\n",
        "#Get encoded output of input images = Latent space\n",
        "encoded_images = encoder_model.predict_generator(train_generator)"
      ],
      "metadata": {
        "id": "NmwYQEq2QwrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the encoder output because KDE from sklearn takes 1D vectors as input\n",
        "encoder_output_shape = encoder_model.output_shape #Here, we have 16x16x16\n",
        "out_vector_shape = encoder_output_shape[1]*encoder_output_shape[2]*encoder_output_shape[3]\n",
        "\n",
        "encoded_images_vector = [np.reshape(img, (out_vector_shape)) for img in encoded_images]"
      ],
      "metadata": {
        "id": "WdrkUwIIQwpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit KDE to the image latent data\n",
        "kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_images_vector)"
      ],
      "metadata": {
        "id": "p3qldSe4Qwnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate density and reconstruction error to find their means values for\n",
        "#good and anomaly images. \n",
        "#We use these mean and sigma to set thresholds. \n",
        "def calc_density_and_recon_error(batch_images):\n",
        "    \n",
        "    density_list=[]\n",
        "    recon_error_list=[]\n",
        "    for im in range(0, batch_images.shape[0]-1):\n",
        "        \n",
        "        img  = batch_images[im]\n",
        "        img = img[np.newaxis, :,:,:]\n",
        "        encoded_img = encoder_model.predict([[img]]) # Create a compressed version of the image using the encoder\n",
        "        encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] # Flatten the compressed image\n",
        "        density = kde.score_samples(encoded_img)[0] # get a density score for the new image\n",
        "        reconstruction = model.predict([[img]])\n",
        "        reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
        "        density_list.append(density)\n",
        "        recon_error_list.append(reconstruction_error)\n",
        "        \n",
        "    average_density = np.mean(np.array(density_list))  \n",
        "    stdev_density = np.std(np.array(density_list)) \n",
        "    \n",
        "    average_recon_error = np.mean(np.array(recon_error_list))  \n",
        "    stdev_recon_error = np.std(np.array(recon_error_list)) \n",
        "    \n",
        "    return average_density, stdev_density, average_recon_error, stdev_recon_error"
      ],
      "metadata": {
        "id": "VBpXw4PZQwli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get average and std dev. of density and recon. error for uninfected and anomaly (parasited) images. \n",
        "#For this let us generate a batch of images for each. \n",
        "train_batch = train_generator.next()[0]\n",
        "anomaly_batch = anomaly_generator.next()[0]\n",
        "\n",
        "uninfected_values = calc_density_and_recon_error(train_batch)\n",
        "anomaly_values = calc_density_and_recon_error(anomaly_batch)"
      ],
      "metadata": {
        "id": "DQwQCYqgREzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, input unknown images and sort as Good or Anomaly\n",
        "def check_anomaly(img_path):\n",
        "    density_threshold = 2500 #Set this value based on the above exercise\n",
        "    reconstruction_error_threshold = 0.004 # Set this value based on the above exercise\n",
        "    img  = Image.open(img_path)\n",
        "    img = np.array(img.resize((128,128), Image.ANTIALIAS))\n",
        "    plt.imshow(img)\n",
        "    img = img / 255.\n",
        "    img = img[np.newaxis, :,:,:]\n",
        "    encoded_img = encoder_model.predict([[img]]) \n",
        "    encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] \n",
        "    density = kde.score_samples(encoded_img)[0] \n",
        "\n",
        "    reconstruction = model.predict([[img]])\n",
        "    reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
        "\n",
        "    if density < density_threshold or reconstruction_error > reconstruction_error_threshold:\n",
        "        print(\"The image is an anomaly\")\n",
        "        \n",
        "    else:\n",
        "        print(\"The image is NOT an anomaly\")"
      ],
      "metadata": {
        "id": "Ra9qWKEcREu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load a couple of test images and verify whether they are reported as anomalies.\n",
        "import glob\n",
        "para_file_paths = glob.glob('cell_images2/parasitized/images/*')\n",
        "uninfected_file_paths = glob.glob('cell_images2/uninfected_train/images/*')"
      ],
      "metadata": {
        "id": "R23gOfMlREqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Good/normal image verification\n",
        "num=random.randint(0,len(para_file_paths)-1)\n",
        "check_anomaly(uninfected_file_paths[num])"
      ],
      "metadata": {
        "id": "lkGfAUfiREn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Anomaly image verification\n",
        "num=random.randint(0,len(para_file_paths)-1)\n",
        "check_anomaly(para_file_paths[num])"
      ],
      "metadata": {
        "id": "1WG-etwnRWSD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}